# -*- coding: utf-8 -*-
"""Github-Revision1-Final-MGL-Liver-CNN-LR-RF-SVM-100.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tFki8MagmTQxbwnlu_tiQo6vv3sRwyvS
"""

import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
import matplotlib.pyplot as plt
import seaborn as sn
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import roc_curve

from google.colab import drive
drive.mount('/content/drive')

#Load indian liver patient csv file
Liv_D_data = pd.read_csv('/content/drive/MyDrive/indian_liver_patient.csv')
Liv_D_data.head()

#Checking for null values
Liv_D_data.isnull().sum()

"""Four null values found in the dataset"""

Liv_D_data['Dataset'].value_counts()

Liv_D_data["Gender"] = np.where(Liv_D_data["Gender"] == "Female",1,0)

Liv_D_data

Group1 = Liv_D_data.groupby(["Gender","Dataset"])
Liv_D_data['Albumin_and_Globulin_Ratio'] = Group1['Albumin_and_Globulin_Ratio'].transform(lambda x: x.fillna(x.mean()))
X = Liv_D_data.drop('Dataset',axis=1)
y=Liv_D_data['Dataset']

#dataset splitting of final data
# Scenario-I: 
x_train, x_test, y_train, y_test = train_test_split(X, np.array(y).flatten(), test_size=0.1)
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

#scaler = MinMaxScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)
x_train = x_train.reshape(524,10,1)
x_test = x_test.reshape(59,10,1)

import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Conv1D, MaxPool1D,Flatten,Dense,Dropout,BatchNormalization
from tensorflow.keras.optimizers import Adam, RMSprop,Adagrad, Adadelta, Nadam
from keras.layers.noise import GaussianNoise

input_dim = x_train.shape[1]

from keras.layers import Conv1D, Reshape#, MaxPooling1D
model = Sequential()
#Adding a bit of GaussianNoise also works as regularization
model.add(GaussianNoise(0.05, input_shape=(input_dim,)))
#First two is number of filter + kernel size
model.add(Reshape((input_dim, 1)))
model.add(Conv1D(8, (32), activation='relu',padding='same'))
model.add(BatchNormalization())
model.add(Conv1D(8, (16), activation='relu',padding='same'))
model.add(BatchNormalization())
model.add(Flatten())
model.add(Dropout(0.5))
model.add(Dense(128, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(1, activation='linear'))
model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=[ 'accuracy'])

model.summary()

history = model.fit(x_train,y_train,epochs=10,verbose=1,validation_data=(x_test,y_test))

from keras.models import Model, Sequential
layer_name = 'flatten_1'
FC_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)
F=80
#Name the rows (feature)  as f_0, f_1, f_2...
feature_col=[]
for i in range(F):
    feature_col.append("f_"+str(i))
    i+=1

FC_Orig_features = FC_layer_model.predict(X)


FC_Orig_features_=pd.DataFrame(data=FC_Orig_features,columns=feature_col)
feature_col = np.array(feature_col)
FC_Orig_features_

x_train1, x_test1, y_train1, y_test1 = train_test_split(FC_Orig_features_ , y, test_size=0.1)
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import SGDClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier

from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression
model1=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
    intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=4,
    penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
    verbose=0, warm_start=False)
# knn
model2 = RandomForestClassifier(max_depth=20, random_state=2)
model3 = SVC(gamma='auto')



# fit model
model1.fit(x_train1, y_train1)
model2.fit(x_train1, y_train1)
model3.fit(x_train1, y_train1)

# predict probabilities
pred_prob1 = model1.predict(x_test1)
pred_prob2 = model2.predict(x_test1)
pred_prob3 = model3.predict(x_test1)

pip install joblib

import joblib

# saving our model # model - model , filename-model_jlib
joblib.dump(model1 , '/content/drive/MyDrive/Liver models/CNN-LR')
joblib.dump(model2 , '/content/drive/MyDrive/Liver models/CNN-RF')
joblib.dump(model3 , '/content/drive/MyDrive/Liver models/CNN-SVM')

model11 = joblib.load('/content/drive/MyDrive/Liver models/CNN-LR')
#m_jlib.predict([[5000]])



"""CNN-LR with original features"""

import numpy as np
from sklearn.model_selection import StratifiedKFold
import numpy as np
from sklearn.metrics import confusion_matrix, cohen_kappa_score, matthews_corrcoef
#from sklearn.model_selection import KFold
from sklearn.metrics import classification_report
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
skf = StratifiedKFold(n_splits=50)
skf.get_n_splits(FC_Orig_features_, y)

#print(skf)
accuracy=[]
pre=[]
rec=[]
F1=[]

for train_index, test_index in skf.split(FC_Orig_features_, y):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]
    y_train1, y_test1 = y[train_index], y[test_index]
    y_test1=np.array(y_test1).flatten()
    model1.fit(X_train1, y_train1)
    y_pred8 = model1.predict(X_test1)
    scores = accuracy_score(y_pred8,y_test1)    
    scores1=precision_score(y_pred8,y_test1)
    scores2=recall_score(y_pred8,y_test1)
    scores3=f1_score(y_pred8,y_test1)
    
    accuracy.append(scores)
    pre.append(scores1)
    rec.append(scores2)
    F1.append(scores3)
    matrix=classification_report(y_test1, y_pred8)

    print(matrix)
    matrix1=confusion_matrix(y_test1, y_pred8)
    plt.rcParams.update({'font.size': 25})
    fig, ax = plot_confusion_matrix(conf_mat=matrix1,
                                    colorbar=True,
                                    show_absolute=True,
                                    show_normed=False
                                    )
    plt.show()
    
print(accuracy)
print(pre)
print(rec)
print(F1)

np.array(accuracy).mean(),np.array(pre).mean(), np.array(rec).mean(), np.array(F1).mean()

max_acc = np.amax(np.array(accuracy))
max_pre = np.amax(np.array(pre))
max_rec = np.amax(np.array(rec))
max_f1 = np.amax(np.array(F1))
print(max_acc,      max_pre,    max_rec,      max_f1)

import numpy as np
from sklearn.model_selection import StratifiedKFold
import numpy as np
from sklearn.metrics import confusion_matrix, cohen_kappa_score, matthews_corrcoef
#from sklearn.model_selection import KFold
from sklearn.metrics import classification_report
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
skf = StratifiedKFold(n_splits=40)
skf.get_n_splits(FC_Orig_features_, y)

#print(skf)
accuracy=[]
pre=[]
rec=[]
F1=[]

for train_index, test_index in skf.split(FC_Orig_features_, y):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]
    y_train1, y_test1 = y[train_index], y[test_index]
    y_test1=np.array(y_test1).flatten()
    model1.fit(X_train1, y_train1)
    y_pred8 = model1.predict(X_test1)
    scores = accuracy_score(y_pred8,y_test1)    
    scores1=precision_score(y_pred8,y_test1)
    scores2=recall_score(y_pred8,y_test1)
    scores3=f1_score(y_pred8,y_test1)
    
    accuracy.append(scores)
    pre.append(scores1)
    rec.append(scores2)
    F1.append(scores3)
    matrix=classification_report(y_test1, y_pred8)

    print(matrix)
    matrix1=confusion_matrix(y_test1, y_pred8)
    plt.rcParams.update({'font.size': 25})
    fig, ax = plot_confusion_matrix(conf_mat=matrix1,
                                    colorbar=True,
                                    show_absolute=True,
                                    show_normed=False
                                    )
    plt.show()
print(accuracy)
print(pre)
print(rec)
print(F1)

np.array(accuracy).mean(),np.array(pre).mean(), np.array(rec).mean(), np.array(F1).mean()

max_acc = np.amax(np.array(accuracy))
max_pre = np.amax(np.array(pre))
max_rec = np.amax(np.array(rec))
max_f1 = np.amax(np.array(F1))
print(max_acc,      max_pre,    max_rec,      max_f1)

import numpy as np
from sklearn.model_selection import StratifiedKFold
import numpy as np
from sklearn.metrics import confusion_matrix, cohen_kappa_score, matthews_corrcoef
#from sklearn.model_selection import KFold
from sklearn.metrics import classification_report
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
skf = StratifiedKFold(n_splits=30)
skf.get_n_splits(FC_Orig_features_, y)

#print(skf)
accuracy=[]
pre=[]
rec=[]
F1=[]

for train_index, test_index in skf.split(FC_Orig_features_, y):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]
    y_train1, y_test1 = y[train_index], y[test_index]
    y_test1=np.array(y_test1).flatten()
    model1.fit(X_train1, y_train1)
    y_pred8 = model1.predict(X_test1)
    scores = accuracy_score(y_pred8,y_test1)    
    scores1=precision_score(y_pred8,y_test1)
    scores2=recall_score(y_pred8,y_test1)
    scores3=f1_score(y_pred8,y_test1)
    
    accuracy.append(scores)
    pre.append(scores1)
    rec.append(scores2)
    F1.append(scores3)
    matrix=classification_report(y_test1, y_pred8)

    print(matrix)
    matrix1=confusion_matrix(y_test1, y_pred8)
    plt.rcParams.update({'font.size': 25})
    fig, ax = plot_confusion_matrix(conf_mat=matrix1,
                                    colorbar=True,
                                    show_absolute=True,
                                    show_normed=False
                                    )
    plt.show()
print(accuracy)
print(pre)
print(rec)
print(F1)

np.array(accuracy).mean(),np.array(pre).mean(), np.array(rec).mean(), np.array(F1).mean()

max_acc = np.amax(np.array(accuracy))
max_pre = np.amax(np.array(pre))
max_rec = np.amax(np.array(rec))
max_f1 = np.amax(np.array(F1))
print(max_acc,      max_pre,    max_rec,      max_f1)

import numpy as np
from sklearn.model_selection import StratifiedKFold
import numpy as np
from sklearn.metrics import confusion_matrix, cohen_kappa_score, matthews_corrcoef
#from sklearn.model_selection import KFold
from sklearn.metrics import classification_report
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
skf = StratifiedKFold(n_splits=20)
skf.get_n_splits(FC_Orig_features_, y)

#print(skf)
accuracy=[]
pre=[]
rec=[]
F1=[]

for train_index, test_index in skf.split(FC_Orig_features_, y):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]
    y_train1, y_test1 = y[train_index], y[test_index]
    y_test1=np.array(y_test1).flatten()
    model1.fit(X_train1, y_train1)
    y_pred8 = model1.predict(X_test1)
    scores = accuracy_score(y_pred8,y_test1)    
    scores1=precision_score(y_pred8,y_test1)
    scores2=recall_score(y_pred8,y_test1)
    scores3=f1_score(y_pred8,y_test1)
    
    accuracy.append(scores)
    pre.append(scores1)
    rec.append(scores2)
    F1.append(scores3)
    matrix=classification_report(y_test1, y_pred8)

    print(matrix)
    matrix1=confusion_matrix(y_test1, y_pred8)
    plt.rcParams.update({'font.size': 25})
    fig, ax = plot_confusion_matrix(conf_mat=matrix1,
                                    colorbar=True,
                                    show_absolute=True,
                                    show_normed=False
                                    )
    plt.show()
print(accuracy)
print(pre)
print(rec)
print(F1)

np.array(accuracy).mean(),np.array(pre).mean(), np.array(rec).mean(), np.array(F1).mean()

max_acc = np.amax(np.array(accuracy))
max_pre = np.amax(np.array(pre))
max_rec = np.amax(np.array(rec))
max_f1 = np.amax(np.array(F1))
print(max_acc,      max_pre,    max_rec,      max_f1)

import numpy as np
from sklearn.model_selection import StratifiedKFold
import numpy as np
from sklearn.metrics import confusion_matrix, cohen_kappa_score, matthews_corrcoef
#from sklearn.model_selection import KFold
from sklearn.metrics import classification_report
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
skf = StratifiedKFold(n_splits=10)
skf.get_n_splits(FC_Orig_features_, y)

#print(skf)
accuracy=[]
pre=[]
rec=[]
F1=[]

for train_index, test_index in skf.split(FC_Orig_features_, y):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]
    y_train1, y_test1 = y[train_index], y[test_index]
    y_test1=np.array(y_test1).flatten()
    model1.fit(X_train1, y_train1)
    y_pred8 = model1.predict(X_test1)
    scores = accuracy_score(y_pred8,y_test1)    
    scores1=precision_score(y_pred8,y_test1)
    scores2=recall_score(y_pred8,y_test1)
    scores3=f1_score(y_pred8,y_test1)
    
    accuracy.append(scores)
    pre.append(scores1)
    rec.append(scores2)
    F1.append(scores3)
    matrix=classification_report(y_test1, y_pred8)

    print(matrix)
    matrix1=confusion_matrix(y_test1, y_pred8)
    plt.rcParams.update({'font.size': 25})
    fig, ax = plot_confusion_matrix(conf_mat=matrix1,
                                    colorbar=True,
                                    show_absolute=True,
                                    show_normed=False
                                    )
    plt.show()
print(accuracy)
print(pre)
print(rec)
print(F1)

np.array(accuracy).mean(),np.array(pre).mean(), np.array(rec).mean(), np.array(F1).mean()

max_acc = np.amax(np.array(accuracy))
max_pre = np.amax(np.array(pre))
max_rec = np.amax(np.array(rec))
max_f1 = np.amax(np.array(F1))
print(max_acc,      max_pre,    max_rec,      max_f1)

import numpy as np
from sklearn.model_selection import StratifiedKFold
import numpy as np
from sklearn.metrics import confusion_matrix, cohen_kappa_score, matthews_corrcoef
#from sklearn.model_selection import KFold
from sklearn.metrics import classification_report
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
skf = StratifiedKFold(n_splits=50)
skf.get_n_splits(FC_Orig_features_, y)

#print(skf)
accuracy=[]
pre=[]
rec=[]
F1=[]

for train_index, test_index in skf.split(FC_Orig_features_, y):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]
    y_train1, y_test1 = y[train_index], y[test_index]
    y_test1=np.array(y_test1).flatten()
    model2.fit(X_train1, y_train1)
    y_pred8 = model2.predict(X_test1)
    scores = accuracy_score(y_pred8,y_test1)    
    scores1=precision_score(y_pred8,y_test1)
    scores2=recall_score(y_pred8,y_test1)
    scores3=f1_score(y_pred8,y_test1)
    
    accuracy.append(scores)
    pre.append(scores1)
    rec.append(scores2)
    F1.append(scores3)
    matrix=classification_report(y_test1, y_pred8)

    print(matrix)
    matrix1=confusion_matrix(y_test1, y_pred8)
    plt.rcParams.update({'font.size': 25})
    fig, ax = plot_confusion_matrix(conf_mat=matrix1,
                                    colorbar=True,
                                    show_absolute=True,
                                    show_normed=False
                                    )
    plt.show()
    
print(accuracy)
print(pre)
print(rec)
print(F1)

np.array(accuracy).mean(),np.array(pre).mean(), np.array(rec).mean(), np.array(F1).mean()

np.array(accuracy).mean(),np.array(pre).mean(), np.array(rec).mean(), np.array(F1).mean()
max_acc = np.amax(np.array(accuracy))
max_pre = np.amax(np.array(pre))
max_rec = np.amax(np.array(rec))
max_f1 = np.amax(np.array(F1))
print(max_acc,      max_pre,    max_rec,      max_f1)

import numpy as np
from sklearn.model_selection import StratifiedKFold
import numpy as np
from sklearn.metrics import confusion_matrix, cohen_kappa_score, matthews_corrcoef
#from sklearn.model_selection import KFold
from sklearn.metrics import classification_report
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
skf = StratifiedKFold(n_splits=40)
skf.get_n_splits(FC_Orig_features_, y)

#print(skf)
accuracy=[]
pre=[]
rec=[]
F1=[]

for train_index, test_index in skf.split(FC_Orig_features_, y):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]
    y_train1, y_test1 = y[train_index], y[test_index]
    y_test1=np.array(y_test1).flatten()
    model2.fit(X_train1, y_train1)
    y_pred8 = model2.predict(X_test1)
    scores = accuracy_score(y_pred8,y_test1)    
    scores1=precision_score(y_pred8,y_test1)
    scores2=recall_score(y_pred8,y_test1)
    scores3=f1_score(y_pred8,y_test1)
    
    accuracy.append(scores)
    pre.append(scores1)
    rec.append(scores2)
    F1.append(scores3)
    matrix=classification_report(y_test1, y_pred8)

    print(matrix)
    matrix1=confusion_matrix(y_test1, y_pred8)
    plt.rcParams.update({'font.size': 25})
    fig, ax = plot_confusion_matrix(conf_mat=matrix1,
                                    colorbar=True,
                                    show_absolute=True,
                                    show_normed=False
                                    )
    plt.show()
print(accuracy)
print(pre)
print(rec)
print(F1)

np.array(accuracy).mean(),np.array(pre).mean(), np.array(rec).mean(), np.array(F1).mean()

max_acc = np.amax(np.array(accuracy))
max_pre = np.amax(np.array(pre))
max_rec = np.amax(np.array(rec))
max_f1 = np.amax(np.array(F1))
print(max_acc,      max_pre,    max_rec,      max_f1)

import numpy as np
from sklearn.model_selection import StratifiedKFold
import numpy as np
from sklearn.metrics import confusion_matrix, cohen_kappa_score, matthews_corrcoef
#from sklearn.model_selection import KFold
from sklearn.metrics import classification_report
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
skf = StratifiedKFold(n_splits=30)
skf.get_n_splits(FC_Orig_features_, y)

#print(skf)
accuracy=[]
pre=[]
rec=[]
F1=[]

for train_index, test_index in skf.split(FC_Orig_features_, y):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]
    y_train1, y_test1 = y[train_index], y[test_index]
    y_test1=np.array(y_test1).flatten()
    model2.fit(X_train1, y_train1)
    y_pred8 = model2.predict(X_test1)
    scores = accuracy_score(y_pred8,y_test1)    
    scores1=precision_score(y_pred8,y_test1)
    scores2=recall_score(y_pred8,y_test1)
    scores3=f1_score(y_pred8,y_test1)
    
    accuracy.append(scores)
    pre.append(scores1)
    rec.append(scores2)
    F1.append(scores3)
    matrix=classification_report(y_test1, y_pred8)

    print(matrix)
    matrix1=confusion_matrix(y_test1, y_pred8)
    plt.rcParams.update({'font.size': 25})
    fig, ax = plot_confusion_matrix(conf_mat=matrix1,
                                    colorbar=True,
                                    show_absolute=True,
                                    show_normed=False
                                    )
    plt.show()
print(accuracy)
print(pre)
print(rec)
print(F1)

np.array(accuracy).mean(),np.array(pre).mean(), np.array(rec).mean(), np.array(F1).mean()

max_acc = np.amax(np.array(accuracy))
max_pre = np.amax(np.array(pre))
max_rec = np.amax(np.array(rec))
max_f1 = np.amax(np.array(F1))
print(max_acc,      max_pre,    max_rec,      max_f1)

import numpy as np
from sklearn.model_selection import StratifiedKFold
import numpy as np
from sklearn.metrics import confusion_matrix, cohen_kappa_score, matthews_corrcoef
#from sklearn.model_selection import KFold
from sklearn.metrics import classification_report
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
skf = StratifiedKFold(n_splits=20)
skf.get_n_splits(FC_Orig_features_, y)

#print(skf)
accuracy=[]
pre=[]
rec=[]
F1=[]

for train_index, test_index in skf.split(FC_Orig_features_, y):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]
    y_train1, y_test1 = y[train_index], y[test_index]
    y_test1=np.array(y_test1).flatten()
    model2.fit(X_train1, y_train1)
    y_pred8 = model2.predict(X_test1)
    scores = accuracy_score(y_pred8,y_test1)    
    scores1=precision_score(y_pred8,y_test1)
    scores2=recall_score(y_pred8,y_test1)
    scores3=f1_score(y_pred8,y_test1)
    
    accuracy.append(scores)
    pre.append(scores1)
    rec.append(scores2)
    F1.append(scores3)
    matrix=classification_report(y_test1, y_pred8)

    print(matrix)
    matrix1=confusion_matrix(y_test1, y_pred8)
    plt.rcParams.update({'font.size': 25})
    fig, ax = plot_confusion_matrix(conf_mat=matrix1,
                                    colorbar=True,
                                    show_absolute=True,
                                    show_normed=False
                                    )
    plt.show()
print(accuracy)
print(pre)
print(rec)
print(F1)

np.array(accuracy).mean(),np.array(pre).mean(), np.array(rec).mean(), np.array(F1).mean()

max_acc = np.amax(np.array(accuracy))
max_pre = np.amax(np.array(pre))
max_rec = np.amax(np.array(rec))
max_f1 = np.amax(np.array(F1))
print(max_acc,      max_pre,    max_rec,      max_f1)

import numpy as np
from sklearn.model_selection import StratifiedKFold
import numpy as np
from sklearn.metrics import confusion_matrix, cohen_kappa_score, matthews_corrcoef
#from sklearn.model_selection import KFold
from sklearn.metrics import classification_report
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
skf = StratifiedKFold(n_splits=10)
skf.get_n_splits(FC_Orig_features_, y)

#print(skf)
accuracy=[]
pre=[]
rec=[]
F1=[]

for train_index, test_index in skf.split(FC_Orig_features_, y):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]
    y_train1, y_test1 = y[train_index], y[test_index]
    y_test1=np.array(y_test1).flatten()
    model2.fit(X_train1, y_train1)
    y_pred8 = model2.predict(X_test1)
    scores = accuracy_score(y_pred8,y_test1)    
    scores1=precision_score(y_pred8,y_test1)
    scores2=recall_score(y_pred8,y_test1)
    scores3=f1_score(y_pred8,y_test1)
    
    accuracy.append(scores)
    pre.append(scores1)
    rec.append(scores2)
    F1.append(scores3)
    matrix=classification_report(y_test1, y_pred8)

    print(matrix)
    matrix1=confusion_matrix(y_test1, y_pred8)
    plt.rcParams.update({'font.size': 25})
    fig, ax = plot_confusion_matrix(conf_mat=matrix1,
                                    colorbar=True,
                                    show_absolute=True,
                                    show_normed=False
                                    )
    plt.show()
print(accuracy)
print(pre)
print(rec)
print(F1)

np.array(accuracy).mean(),np.array(pre).mean(), np.array(rec).mean(), np.array(F1).mean()

np.array(accuracy).mean(),np.array(pre).mean(), np.array(rec).mean(), np.array(F1).mean()
max_acc = np.amax(np.array(accuracy))
max_pre = np.amax(np.array(pre))
max_rec = np.amax(np.array(rec))
max_f1 = np.amax(np.array(F1))
print(max_acc,      max_pre,    max_rec,      max_f1)

"""CNN-SVM with original features"""

import numpy as np
from sklearn.model_selection import StratifiedKFold
import numpy as np
from sklearn.metrics import confusion_matrix, cohen_kappa_score, matthews_corrcoef
#from sklearn.model_selection import KFold
from sklearn.metrics import classification_report
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
skf = StratifiedKFold(n_splits=50)
skf.get_n_splits(FC_Orig_features_, y)

#print(skf)
accuracy=[]
pre=[]
rec=[]
F1=[]

for train_index, test_index in skf.split(FC_Orig_features_, y):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]
    y_train1, y_test1 = y[train_index], y[test_index]
    y_test1=np.array(y_test1).flatten()
    model3.fit(X_train1, y_train1)
    y_pred8 = model3.predict(X_test1)
    scores = accuracy_score(y_pred8,y_test1)    
    scores1=precision_score(y_pred8,y_test1)
    scores2=recall_score(y_pred8,y_test1)
    scores3=f1_score(y_pred8,y_test1)
    
    accuracy.append(scores)
    pre.append(scores1)
    rec.append(scores2)
    F1.append(scores3)
    matrix=classification_report(y_test1, y_pred8)

    print(matrix)
    matrix1=confusion_matrix(y_test1, y_pred8)
    plt.rcParams.update({'font.size': 25})
    fig, ax = plot_confusion_matrix(conf_mat=matrix1,
                                    colorbar=True,
                                    show_absolute=True,
                                    show_normed=False
                                    )
    plt.show()
    
print(accuracy)
print(pre)
print(rec)
print(F1)

np.array(accuracy).mean(),np.array(pre).mean(), np.array(rec).mean(), np.array(F1).mean()

max_acc = np.amax(np.array(accuracy))
max_pre = np.amax(np.array(pre))
max_rec = np.amax(np.array(rec))
max_f1 = np.amax(np.array(F1))
print(max_acc,      max_pre,    max_rec,      max_f1)

import numpy as np
from sklearn.model_selection import StratifiedKFold
import numpy as np
from sklearn.metrics import confusion_matrix, cohen_kappa_score, matthews_corrcoef
#from sklearn.model_selection import KFold
from sklearn.metrics import classification_report
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
skf = StratifiedKFold(n_splits=40)
skf.get_n_splits(FC_Orig_features_, y)

#print(skf)
accuracy=[]
pre=[]
rec=[]
F1=[]

for train_index, test_index in skf.split(FC_Orig_features_, y):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]
    y_train1, y_test1 = y[train_index], y[test_index]
    y_test1=np.array(y_test1).flatten()
    model3.fit(X_train1, y_train1)
    y_pred8 = model3.predict(X_test1)
    scores = accuracy_score(y_pred8,y_test1)    
    scores1=precision_score(y_pred8,y_test1)
    scores2=recall_score(y_pred8,y_test1)
    scores3=f1_score(y_pred8,y_test1)
    
    accuracy.append(scores)
    pre.append(scores1)
    rec.append(scores2)
    F1.append(scores3)
    matrix=classification_report(y_test1, y_pred8)

    print(matrix)
    matrix1=confusion_matrix(y_test1, y_pred8)
    plt.rcParams.update({'font.size': 25})
    fig, ax = plot_confusion_matrix(conf_mat=matrix1,
                                    colorbar=True,
                                    show_absolute=True,
                                    show_normed=False
                                    )
    plt.show()
print(accuracy)
print(pre)
print(rec)
print(F1)

np.array(accuracy).mean(),np.array(pre).mean(), np.array(rec).mean(), np.array(F1).mean()

max_acc = np.amax(np.array(accuracy))
max_pre = np.amax(np.array(pre))
max_rec = np.amax(np.array(rec))
max_f1 = np.amax(np.array(F1))
print(max_acc,      max_pre,    max_rec,      max_f1)

import numpy as np
from sklearn.model_selection import StratifiedKFold
import numpy as np
from sklearn.metrics import confusion_matrix, cohen_kappa_score, matthews_corrcoef
#from sklearn.model_selection import KFold
from sklearn.metrics import classification_report
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
skf = StratifiedKFold(n_splits=10)
skf.get_n_splits(FC_Orig_features_, y)

#print(skf)
accuracy=[]
pre=[]
rec=[]
F1=[]

for train_index, test_index in skf.split(FC_Orig_features_, y):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]
    y_train1, y_test1 = y[train_index], y[test_index]
    y_test1=np.array(y_test1).flatten()
    model3.fit(X_train1, y_train1)
    y_pred8 = model3.predict(X_test1)
    scores = accuracy_score(y_pred8,y_test1)    
    scores1=precision_score(y_pred8,y_test1)
    scores2=recall_score(y_pred8,y_test1)
    scores3=f1_score(y_pred8,y_test1)
    
    accuracy.append(scores)
    pre.append(scores1)
    rec.append(scores2)
    F1.append(scores3)
    matrix=classification_report(y_test1, y_pred8)

    print(matrix)
    matrix1=confusion_matrix(y_test1, y_pred8)
    plt.rcParams.update({'font.size': 25})
    fig, ax = plot_confusion_matrix(conf_mat=matrix1,
                                    colorbar=True,
                                    show_absolute=True,
                                    show_normed=False
                                    )
    plt.show()
print(accuracy)
print(pre)
print(rec)
print(F1)

np.array(accuracy).mean(),np.array(pre).mean(), np.array(rec).mean(), np.array(F1).mean()

max_acc = np.amax(np.array(accuracy))
max_pre = np.amax(np.array(pre))
max_rec = np.amax(np.array(rec))
max_f1 = np.amax(np.array(F1))
print(max_acc,      max_pre,    max_rec,      max_f1)

import numpy as np
from sklearn.model_selection import StratifiedKFold
import numpy as np
from sklearn.metrics import confusion_matrix, cohen_kappa_score, matthews_corrcoef
#from sklearn.model_selection import KFold
from sklearn.metrics import classification_report
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
skf = StratifiedKFold(n_splits=30)
skf.get_n_splits(FC_Orig_features_, y)

#print(skf)
accuracy=[]
pre=[]
rec=[]
F1=[]

for train_index, test_index in skf.split(FC_Orig_features_, y):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]
    y_train1, y_test1 = y[train_index], y[test_index]
    y_test1=np.array(y_test1).flatten()
    model3.fit(X_train1, y_train1)
    y_pred8 = model3.predict(X_test1)
    scores = accuracy_score(y_pred8,y_test1)    
    scores1=precision_score(y_pred8,y_test1)
    scores2=recall_score(y_pred8,y_test1)
    scores3=f1_score(y_pred8,y_test1)
    
    accuracy.append(scores)
    pre.append(scores1)
    rec.append(scores2)
    F1.append(scores3)
    matrix=classification_report(y_test1, y_pred8)

    print(matrix)
    matrix1=confusion_matrix(y_test1, y_pred8)
    plt.rcParams.update({'font.size': 25})
    fig, ax = plot_confusion_matrix(conf_mat=matrix1,
                                    colorbar=True,
                                    show_absolute=True,
                                    show_normed=False
                                    )
    plt.show()
print(accuracy)
print(pre)
print(rec)
print(F1)

np.array(accuracy).mean(),np.array(pre).mean(), np.array(rec).mean(), np.array(F1).mean()

max_acc = np.amax(np.array(accuracy))
max_pre = np.amax(np.array(pre))
max_rec = np.amax(np.array(rec))
max_f1 = np.amax(np.array(F1))
print(max_acc,      max_pre,    max_rec,      max_f1)

import numpy as np
from sklearn.model_selection import StratifiedKFold
import numpy as np
from sklearn.metrics import confusion_matrix, cohen_kappa_score, matthews_corrcoef
#from sklearn.model_selection import KFold
from sklearn.metrics import classification_report
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
skf = StratifiedKFold(n_splits=20)
skf.get_n_splits(FC_Orig_features_, y)

#print(skf)
accuracy=[]
pre=[]
rec=[]
F1=[]

for train_index, test_index in skf.split(FC_Orig_features_, y):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]
    y_train1, y_test1 = y[train_index], y[test_index]
    y_test1=np.array(y_test1).flatten()
    model3.fit(X_train1, y_train1)
    y_pred8 = model3.predict(X_test1)
    scores = accuracy_score(y_pred8,y_test1)    
    scores1=precision_score(y_pred8,y_test1)
    scores2=recall_score(y_pred8,y_test1)
    scores3=f1_score(y_pred8,y_test1)
    
    accuracy.append(scores)
    pre.append(scores1)
    rec.append(scores2)
    F1.append(scores3)
    matrix=classification_report(y_test1, y_pred8)

    print(matrix)
    matrix1=confusion_matrix(y_test1, y_pred8)
    plt.rcParams.update({'font.size': 25})
    fig, ax = plot_confusion_matrix(conf_mat=matrix1,
                                    colorbar=True,
                                    show_absolute=True,
                                    show_normed=False
                                    )
    plt.show()
print(accuracy)
print(pre)
print(rec)
print(F1)

np.array(accuracy).mean(),np.array(pre).mean(), np.array(rec).mean(), np.array(F1).mean()

max_acc = np.amax(np.array(accuracy))
max_pre = np.amax(np.array(pre))
max_rec = np.amax(np.array(rec))
max_f1 = np.amax(np.array(F1))
print(max_acc,      max_pre,    max_rec,      max_f1)

import numpy as np
from sklearn.model_selection import StratifiedKFold
import numpy as np
from sklearn.metrics import confusion_matrix, cohen_kappa_score, matthews_corrcoef
#from sklearn.model_selection import KFold
from sklearn.metrics import classification_report
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
skf = StratifiedKFold(n_splits=10)
skf.get_n_splits(FC_Orig_features_, y)

#print(skf)
accuracy=[]
pre=[]
rec=[]
F1=[]

for train_index, test_index in skf.split(FC_Orig_features_, y):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]
    y_train1, y_test1 = y[train_index], y[test_index]
    y_test1=np.array(y_test1).flatten()
    model3.fit(X_train1, y_train1)
    y_pred8 = model3.predict(X_test1)
    scores = accuracy_score(y_pred8,y_test1)    
    scores1=precision_score(y_pred8,y_test1)
    scores2=recall_score(y_pred8,y_test1)
    scores3=f1_score(y_pred8,y_test1)
    
    accuracy.append(scores)
    pre.append(scores1)
    rec.append(scores2)
    F1.append(scores3)
    matrix=classification_report(y_test1, y_pred8)

    print(matrix)
    matrix1=confusion_matrix(y_test1, y_pred8)
    plt.rcParams.update({'font.size': 25})
    fig, ax = plot_confusion_matrix(conf_mat=matrix1,
                                    colorbar=True,
                                    show_absolute=True,
                                    show_normed=False
                                    )
    plt.show()
print(accuracy)
print(pre)
print(rec)
print(F1)

np.array(accuracy).mean(),np.array(pre).mean(), np.array(rec).mean(), np.array(F1).mean()

max_acc = np.amax(np.array(accuracy))
max_pre = np.amax(np.array(pre))
max_rec = np.amax(np.array(rec))
max_f1 = np.amax(np.array(F1))
print(max_acc,      max_pre,    max_rec,      max_f1)

"""CNN with extra tree classifier"""

from sklearn.ensemble import ExtraTreesClassifier
import matplotlib.pyplot as plt
model = ExtraTreesClassifier()
model.fit(FC_Orig_features_,y)
print(model.feature_names_in_) #use inbuilt class feature_importances of tree based classifiers
print(model.feature_importances_)
#plot graph of feature importances for better visualization
feat_importances = pd.Series(model.feature_importances_, index=FC_Orig_features_.columns)
feat_importances.nlargest(10).plot(kind='barh')
plt.show()

Extra_tree_features=FC_Orig_features_[['f_13' ,'f_29', 'f_22', 'f_0', 'f_30', 'f_42', 'f_39', 'f_6' ,'f_52', 'f_67']]

x_train1, x_test1, y_train1, y_test1 = train_test_split(Extra_tree_features , y, test_size=0.1)
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import SGDClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier

from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression
model1=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
    intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=4,
    penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
    verbose=0, warm_start=False)
# knn
model2 = RandomForestClassifier(max_depth=20, random_state=2)
model3 = SVC(gamma='auto')



# fit model
model1.fit(x_train1, y_train1)
model2.fit(x_train1, y_train1)
model3.fit(x_train1, y_train1)

# predict probabilities
pred_prob1 = model1.predict(x_test1)
pred_prob2 = model2.predict(x_test1)
pred_prob3 = model3.predict(x_test1)
joblib.dump(model1 , '/content/drive/MyDrive/Liver models/CNN-LR-ET')
joblib.dump(model2 , '/content/drive/MyDrive/Liver models/CNN-RF-ET')
joblib.dump(model3 , '/content/drive/MyDrive/Liver models/CNN-SVM-ET')

joblib.dump(model1 , '/content/drive/MyDrive/Liver models/CNN-LR-ET')
joblib.dump(model2 , '/content/drive/MyDrive/Liver models/CNN-RF-ET')
joblib.dump(model3 , '/content/drive/MyDrive/Liver models/CNN-SVM-ET')

import numpy as np
from sklearn.model_selection import StratifiedKFold
import numpy as np
from sklearn.metrics import confusion_matrix, cohen_kappa_score, matthews_corrcoef
#from sklearn.model_selection import KFold
from sklearn.metrics import classification_report
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
skf = StratifiedKFold(n_splits=50)
skf.get_n_splits(Extra_tree_features, y)

#print(skf)
accuracy=[]
pre=[]
rec=[]
F1=[]

for train_index, test_index in skf.split(Extra_tree_features, y):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]
    y_train1, y_test1 = y[train_index], y[test_index]
    y_test1=np.array(y_test1).flatten()
    model1.fit(X_train1, y_train1)
    y_pred8 = model1.predict(X_test1)
    scores = accuracy_score(y_pred8,y_test1)    
    scores1=precision_score(y_pred8,y_test1)
    scores2=recall_score(y_pred8,y_test1)
    scores3=f1_score(y_pred8,y_test1)
    
    accuracy.append(scores)
    pre.append(scores1)
    rec.append(scores2)
    F1.append(scores3)
    matrix=classification_report(y_test1, y_pred8)

    print(matrix)
    matrix1=confusion_matrix(y_test1, y_pred8)
    plt.rcParams.update({'font.size': 25})
    fig, ax = plot_confusion_matrix(conf_mat=matrix1,
                                    colorbar=True,
                                    show_absolute=True,
                                    show_normed=False
                                    )
    plt.show()
print(accuracy)
print(pre)
print(rec)
print(F1)

np.array(accuracy).mean(),np.array(pre).mean(), np.array(rec).mean(), np.array(F1).mean()

max_acc = np.amax(np.array(accuracy))
max_pre = np.amax(np.array(pre))
max_rec = np.amax(np.array(rec))
max_f1 = np.amax(np.array(F1))
print(max_acc,      max_pre,    max_rec,      max_f1)

import numpy as np
from sklearn.model_selection import StratifiedKFold
import numpy as np
from sklearn.metrics import confusion_matrix, cohen_kappa_score, matthews_corrcoef
#from sklearn.model_selection import KFold
from sklearn.metrics import classification_report
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
skf = StratifiedKFold(n_splits=40)
skf.get_n_splits(Extra_tree_features, y)

#print(skf)
accuracy=[]
pre=[]
rec=[]
F1=[]

for train_index, test_index in skf.split(Extra_tree_features, y):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]
    y_train1, y_test1 = y[train_index], y[test_index]
    y_test1=np.array(y_test1).flatten()
    model1.fit(X_train1, y_train1)
    y_pred8 = model1.predict(X_test1)
    scores = accuracy_score(y_pred8,y_test1)    
    scores1=precision_score(y_pred8,y_test1)
    scores2=recall_score(y_pred8,y_test1)
    scores3=f1_score(y_pred8,y_test1)
    
    accuracy.append(scores)
    pre.append(scores1)
    rec.append(scores2)
    F1.append(scores3)
    matrix=classification_report(y_test1, y_pred8)

    print(matrix)
    matrix1=confusion_matrix(y_test1, y_pred8)
    plt.rcParams.update({'font.size': 25})
    fig, ax = plot_confusion_matrix(conf_mat=matrix1,
                                    colorbar=True,
                                    show_absolute=True,
                                    show_normed=False
                                    )
    plt.show()
print(accuracy)
print(pre)
print(rec)
print(F1)

np.array(accuracy).mean(),np.array(pre).mean(), np.array(rec).mean(), np.array(F1).mean()

max_acc = np.amax(np.array(accuracy))
max_pre = np.amax(np.array(pre))
max_rec = np.amax(np.array(rec))
max_f1 = np.amax(np.array(F1))
print(max_acc,      max_pre,    max_rec,      max_f1)

import numpy as np
from sklearn.model_selection import StratifiedKFold
import numpy as np
from sklearn.metrics import confusion_matrix, cohen_kappa_score, matthews_corrcoef
#from sklearn.model_selection import KFold
from sklearn.metrics import classification_report
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
skf = StratifiedKFold(n_splits=30)
skf.get_n_splits(Extra_tree_features, y)

#print(skf)
accuracy=[]
pre=[]
rec=[]
F1=[]

for train_index, test_index in skf.split(Extra_tree_features, y):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]
    y_train1, y_test1 = y[train_index], y[test_index]
    y_test1=np.array(y_test1).flatten()
    model1.fit(X_train1, y_train1)
    y_pred8 = model1.predict(X_test1)
    scores = accuracy_score(y_pred8,y_test1)    
    scores1=precision_score(y_pred8,y_test1)
    scores2=recall_score(y_pred8,y_test1)
    scores3=f1_score(y_pred8,y_test1)
    
    accuracy.append(scores)
    pre.append(scores1)
    rec.append(scores2)
    F1.append(scores3)
    matrix=classification_report(y_test1, y_pred8)

    print(matrix)
    matrix1=confusion_matrix(y_test1, y_pred8)
    plt.rcParams.update({'font.size': 25})
    fig, ax = plot_confusion_matrix(conf_mat=matrix1,
                                    colorbar=True,
                                    show_absolute=True,
                                    show_normed=False
                                    )
    plt.show()
print(accuracy)
print(pre)
print(rec)
print(F1)

np.array(accuracy).mean(),np.array(pre).mean(), np.array(rec).mean(), np.array(F1).mean()

max_acc = np.amax(np.array(accuracy))
max_pre = np.amax(np.array(pre))
max_rec = np.amax(np.array(rec))
max_f1 = np.amax(np.array(F1))
print(max_acc,      max_pre,    max_rec,      max_f1)

import numpy as np
from sklearn.model_selection import StratifiedKFold
import numpy as np
from sklearn.metrics import confusion_matrix, cohen_kappa_score, matthews_corrcoef
#from sklearn.model_selection import KFold
from sklearn.metrics import classification_report
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
skf = StratifiedKFold(n_splits=20)
skf.get_n_splits(Extra_tree_features, y)

#print(skf)
accuracy=[]
pre=[]
rec=[]
F1=[]

for train_index, test_index in skf.split(Extra_tree_features, y):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]
    y_train1, y_test1 = y[train_index], y[test_index]
    y_test1=np.array(y_test1).flatten()
    model1.fit(X_train1, y_train1)
    y_pred8 = model1.predict(X_test1)
    scores = accuracy_score(y_pred8,y_test1)    
    scores1=precision_score(y_pred8,y_test1)
    scores2=recall_score(y_pred8,y_test1)
    scores3=f1_score(y_pred8,y_test1)
    
    accuracy.append(scores)
    pre.append(scores1)
    rec.append(scores2)
    F1.append(scores3)
    matrix=classification_report(y_test1, y_pred8)

    print(matrix)
    matrix1=confusion_matrix(y_test1, y_pred8)
    plt.rcParams.update({'font.size': 25})
    fig, ax = plot_confusion_matrix(conf_mat=matrix1,
                                    colorbar=True,
                                    show_absolute=True,
                                    show_normed=False
                                    )
    plt.show()
print(accuracy)
print(pre)
print(rec)
print(F1)

np.array(accuracy).mean(),np.array(pre).mean(), np.array(rec).mean(), np.array(F1).mean()

max_acc = np.amax(np.array(accuracy))
max_pre = np.amax(np.array(pre))
max_rec = np.amax(np.array(rec))
max_f1 = np.amax(np.array(F1))
print(max_acc,      max_pre,    max_rec,      max_f1)

import numpy as np
from sklearn.model_selection import StratifiedKFold
import numpy as np
from sklearn.metrics import confusion_matrix, cohen_kappa_score, matthews_corrcoef
#from sklearn.model_selection import KFold
from sklearn.metrics import classification_report
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
skf = StratifiedKFold(n_splits=10)
skf.get_n_splits(Extra_tree_features, y)

#print(skf)
accuracy=[]
pre=[]
rec=[]
F1=[]

for train_index, test_index in skf.split(Extra_tree_features, y):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]
    y_train1, y_test1 = y[train_index], y[test_index]
    y_test1=np.array(y_test1).flatten()
    model1.fit(X_train1, y_train1)
    y_pred8 = model1.predict(X_test1)
    scores = accuracy_score(y_pred8,y_test1)    
    scores1=precision_score(y_pred8,y_test1)
    scores2=recall_score(y_pred8,y_test1)
    scores3=f1_score(y_pred8,y_test1)
    
    accuracy.append(scores)
    pre.append(scores1)
    rec.append(scores2)
    F1.append(scores3)
    matrix=classification_report(y_test1, y_pred8)

    print(matrix)
    matrix1=confusion_matrix(y_test1, y_pred8)
    plt.rcParams.update({'font.size': 25})
    fig, ax = plot_confusion_matrix(conf_mat=matrix1,
                                    colorbar=True,
                                    show_absolute=True,
                                    show_normed=False
                                    )
    plt.show()
print(accuracy)
print(pre)
print(rec)
print(F1)

np.array(accuracy).mean(),np.array(pre).mean(), np.array(rec).mean(), np.array(F1).mean()

max_acc = np.amax(np.array(accuracy))
max_pre = np.amax(np.array(pre))
max_rec = np.amax(np.array(rec))
max_f1 = np.amax(np.array(F1))
print(max_acc,      max_pre,    max_rec,      max_f1)

!pip install mrmr_selection

from mrmr import mrmr_classif
from sklearn.datasets import make_classification
# use mrmr classification
selected_features = mrmr_classif(FC_Orig_features_, y, K = 10)
selected_features

"""CNN with MRMR feature extraction technique"""

mrmr_features=FC_Orig_features_[['f_39', 'f_57', 'f_67', 'f_19', 'f_42', 'f_6', 'f_9', 'f_66', 'f_68', 'f_30']]
mrmr_features

x_train1, x_test1, y_train1, y_test1 = train_test_split(mrmr_features , y, test_size=0.1)
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import SGDClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier

from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression
model1=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
    intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=4,
    penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
    verbose=0, warm_start=False)
# knn
model2 = RandomForestClassifier(max_depth=20, random_state=2)
model3 = SVC(gamma='auto')



# fit model
model1.fit(x_train1, y_train1)
model2.fit(x_train1, y_train1)
model3.fit(x_train1, y_train1)

# predict probabilities
pred_prob1 = model1.predict(x_test1)
pred_prob2 = model2.predict(x_test1)
pred_prob3 = model3.predict(x_test1)
joblib.dump(model1 , '/content/drive/MyDrive/Liver models/CNN-LR-MR')
joblib.dump(model2 , '/content/drive/MyDrive/Liver models/CNN-RF-MR')
joblib.dump(model3 , '/content/drive/MyDrive/Liver models/CNN-SVM-MR')

import numpy as np
from sklearn.model_selection import StratifiedKFold
import numpy as np
from sklearn.metrics import confusion_matrix, cohen_kappa_score, matthews_corrcoef
#from sklearn.model_selection import KFold
from sklearn.metrics import classification_report
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
skf = StratifiedKFold(n_splits=40)
skf.get_n_splits(mrmr_features, y)

#print(skf)
accuracy=[]
pre=[]
rec=[]
F1=[]

for train_index, test_index in skf.split(mrmr_features, y):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]
    y_train1, y_test1 = y[train_index], y[test_index]
    y_test1=np.array(y_test1).flatten()
    model3.fit(X_train1, y_train1)
    y_pred8 = model3.predict(X_test1)
    scores = accuracy_score(y_pred8,y_test1)    
    scores1=precision_score(y_pred8,y_test1)
    scores2=recall_score(y_pred8,y_test1)
    scores3=f1_score(y_pred8,y_test1)
    
    accuracy.append(scores)
    pre.append(scores1)
    rec.append(scores2)
    F1.append(scores3)
    matrix=classification_report(y_test1, y_pred8)

    print(matrix)
    matrix1=confusion_matrix(y_test1, y_pred8)
    plt.rcParams.update({'font.size': 25})
    fig, ax = plot_confusion_matrix(conf_mat=matrix1,
                                    colorbar=True,
                                    show_absolute=True,
                                    show_normed=False
                                    )
    plt.show()
print(accuracy)
print(pre)
print(rec)
print(F1)

np.array(accuracy).mean(),np.array(pre).mean(), np.array(rec).mean(), np.array(F1).mean()

max_acc = np.amax(np.array(accuracy))
max_pre = np.amax(np.array(pre))
max_rec = np.amax(np.array(rec))
max_f1 = np.amax(np.array(F1))
print(max_acc,      max_pre,    max_rec,      max_f1)